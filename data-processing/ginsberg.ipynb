{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "A\n",
      "B\n",
      "C\n",
      "D\n",
      "E\n",
      "F\n",
      "G\n",
      "H\n",
      "I\n",
      "J\n",
      "K\n",
      "L\n",
      "M\n",
      "N\n",
      "O\n",
      "P\n",
      "Q\n",
      "R\n",
      "S\n",
      "T\n",
      "U\n",
      "V\n",
      "W\n",
      "X\n",
      "Y\n",
      "Z\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "import os\n",
    "import html\n",
    "\n",
    "results = {}\n",
    "max_length = 15\n",
    "\n",
    "def main():\n",
    "    #filename = 'C:\\\\Users\\\\ben_z\\\\Desktop\\\\save\\\\Clue database\\\\clues.csv'\n",
    "    # with open(filename) as csv_file:\n",
    "    #     csv_reader = csv.reader(csv_file)\n",
    "    #     line_count = 0\n",
    "    #     for row in csv_reader:\n",
    "    #         if(line_count % 10000 == 0):\n",
    "    #             print(f'{line_count:,}')\n",
    "    #         mine_phrases(row[0], max_length)\n",
    "    #         mine_phrases(row[1], max_length)\n",
    "    #         line_count += 1\n",
    "\n",
    "    # filename = 'C:\\\\Users\\\\ben_z\\\\Downloads\\\\mbdump\\\\mbdump\\\\release'\n",
    "    # file1 = open(filename, encoding=\"utf8\")\n",
    "    # line_count = 0\n",
    "    # prev_line = ''\n",
    "    # while True:\n",
    "    #     line_count += 1\n",
    "    #     if(line_count % 10000 == 0):\n",
    "    #         print(f'{line_count:,}')\n",
    "    #     #if (line_count > 10):\n",
    "    #     #    break\n",
    "    #     line = file1.readline()\n",
    "    #     if not line:\n",
    "    #         break\n",
    "    #     tokens = line.split('\\t')\n",
    "    #     if (tokens[2] == prev_line):\n",
    "    #         continue\n",
    "    #     mine_phrases(tokens[2], max_length)\n",
    "    #     prev_line = tokens[2]\n",
    "    # file1.close()\n",
    "\n",
    "    # directory = \"C:\\\\Users\\\\ben_z\\\\Downloads\\\\podcasts-transcripts-3to5\\\\spotify-podcasts-2020\\\\podcasts-transcripts\\\\5\"\n",
    "    # alpha_dirs = os.listdir(directory)\n",
    "    # for alpha in alpha_dirs:\n",
    "    #     print(alpha)\n",
    "    #     pod_dirs = os.listdir(f\"{directory}\\\\{alpha}\")\n",
    "    #     for pod_dir in pod_dirs:\n",
    "    #         episodes = os.listdir(f\"{directory}\\\\{alpha}\\\\{pod_dir}\")\n",
    "    #         for episode in episodes:\n",
    "    #             mine_pod_episode(f\"{directory}\\\\{alpha}\\\\{pod_dir}\\\\{episode}\")\n",
    "\n",
    "    # filename = \"C:\\\\Users\\\\ben_z\\\\Downloads\\\\metadata.json\"\n",
    "    # mine_amazon_products(filename)\n",
    "\n",
    "    # with open('podcasts_5.txt', 'w') as f:\n",
    "    #     for k, v in sorted(results.items()):\n",
    "    #         print(f\"{k},\\\"{v['raw']}\\\",{v['count']}\", file=f)\n",
    "\n",
    "def mine_pod_episode(filename):\n",
    "    file1 = open(filename, encoding=\"utf8\")\n",
    "    line = file1.readline()\n",
    "    transcripts = re.findall(\"\\\"transcript\\\": \\\".*?\\\"\", line)\n",
    "    for transcript in transcripts:\n",
    "        text_search = re.search(\"\\\"transcript\\\": \\\"(.*?)\\\"\", transcript)\n",
    "        text = text_search.group(1)\n",
    "        mine_phrases(text, max_length)\n",
    "    file1.close()\n",
    "\n",
    "def mine_amazon_products(filename):\n",
    "    file1 = open(filename, encoding=\"utf8\")\n",
    "    line_count = 0\n",
    "    while True:\n",
    "        line_count += 1\n",
    "        if(line_count % 1000 == 0):\n",
    "            print(f'{line_count:,}')\n",
    "        #if (line_count > 10):\n",
    "        #    break\n",
    "        line = file1.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        title = re.search(r\"'title': ([\\\"'])([^\\1]+?)\\1\", line)\n",
    "        if not title:\n",
    "            continue\n",
    "        text = html.unescape(title.group(2))\n",
    "        mine_phrases(text, max_length)\n",
    "    file1.close()\n",
    "\n",
    "def mine_phrases(input, max_length):\n",
    "    phrases = []\n",
    "    words = input.split()\n",
    "    for cur_base_index in range(len(words)):\n",
    "        last_index = cur_base_index\n",
    "        cur_raw = normalize_raw(words[last_index])\n",
    "        if (len(cur_raw) == 0):\n",
    "            continue\n",
    "        while(True):\n",
    "            trimmed = normalize_entry(cur_raw)\n",
    "            add_to_results(cur_raw, trimmed)\n",
    "\n",
    "            last_index += 1\n",
    "            if (last_index >= len(words)):\n",
    "                break\n",
    "            next_trimmed_len = len(normalize_entry(words[last_index]))\n",
    "            if (len(trimmed) + next_trimmed_len > max_length):\n",
    "                break\n",
    "            cur_raw += ' ' + normalize_raw(words[last_index])\n",
    "\n",
    "def add_to_results(raw, trimmed):\n",
    "    if (len(trimmed) == 0):\n",
    "        return\n",
    "    if (trimmed in results):\n",
    "        results[trimmed]['count'] += 1\n",
    "    else:\n",
    "        results[trimmed] = {'raw': raw, 'count': 1}\n",
    "\n",
    "def normalize_entry(input):\n",
    "    return re.sub('[^a-zA-Z]+', '', input).upper()\n",
    "\n",
    "def normalize_raw(input):\n",
    "    return re.sub(\"[^0-9a-zA-Z\\-.&',]+\", '', input)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "   main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "def main():\n",
    "    print(\"hi\")\n",
    "    return\n",
    "\n",
    "    directory = \"C:\\\\git2\\\\crosswords-dicts\\\\data-processing\"\n",
    "    for n in range(0, 8):\n",
    "        line_number = 0\n",
    "        filename = directory + f\"\\\\podcasts_{n}.txt\"\n",
    "        print(filename)\n",
    "        file1 = open(filename, encoding=\"utf8\")\n",
    "        while True:\n",
    "            if (line_number % 100_000 == 0):\n",
    "                print(line_number)\n",
    "            line_number += 1\n",
    "            #if (line_number > 100_000):\n",
    "            #    break\n",
    "            line = file1.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            tokens = line.split(',')\n",
    "            normalized = tokens[0]\n",
    "            count = tokens[-1]\n",
    "            definition = (','.join(tokens[1:-1]))[1:-1]\n",
    "            add_to_results(definition, normalized, count)\n",
    "        file1.close()\n",
    "\n",
    "    with open('podcasts_merged.txt', 'w') as f:\n",
    "        for k, v in sorted(results.items()):\n",
    "            score = int(v['count'])\n",
    "            if (score > 4):\n",
    "                print(f\"{k},\\\"{v['raw']}\\\",{v['count']}\", file=f)\n",
    "\n",
    "def add_to_results(raw, trimmed, count):\n",
    "    if (len(trimmed) == 0):\n",
    "        return\n",
    "    if (trimmed in results):\n",
    "        results[trimmed]['count'] += int(count)\n",
    "    else:\n",
    "        results[trimmed] = {'raw': raw, 'count': int(count)}\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "   main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = \"C:\\\\Users\\\\ben_z\\\\Downloads\\\\SBW-vectors-300-min5-skipgram.txt\"\n",
    "results = []\n",
    "\n",
    "\n",
    "\n",
    "# file1 = open(filename, encoding=\"utf8\")\n",
    "# lineno = 0\n",
    "# while True:\n",
    "#     if (lineno % 10000 == 0):\n",
    "#         print(lineno)\n",
    "#     lineno += 1\n",
    "#     line = file1.readline()\n",
    "#     if not line:\n",
    "#         break\n",
    "#     tokens = line.split()\n",
    "#     results.append(tokens[0])\n",
    "# file1.close()\n",
    "\n",
    "# with open('spanish_vectors.txt', 'w', encoding=\"utf8\") as f:\n",
    "#     for r in results:\n",
    "#         print(r, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "B\n",
      "0\n",
      "100000\n",
      "200000\n",
      "C\n",
      "D\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# podcastFilename = \"C:\\\\Users\\\\ben_z\\\\Desktop\\\\entriesData\\\\podcasts_merged.txt\"\n",
    "# wlFilename = \"C:\\\\Users\\\\ben_z\\\\Downloads\\\\rectifiedWordList.dict\"\n",
    "# #outputFilename = \"C:\\\\Users\\\\ben_z\\\\Desktop\\\\rectifiedWordListSpaced.dict\"\n",
    "# #outputFilename = \"C:\\\\Users\\\\ben_z\\\\Desktop\\\\rectifiedWordListWithRaw.dict\"\n",
    "# outputFilename = \"C:\\\\Users\\\\ben_z\\\\Desktop\\\\rectifiedWordListNew.dict\"\n",
    "# results = {}\n",
    "# resultKeys = []\n",
    "# i = 0\n",
    "\n",
    "# wlFile = open(wlFilename)\n",
    "# podcastFile = open(podcastFilename)\n",
    "# outputFile = open(outputFilename, 'w')\n",
    "# podLine = podcastFile.readline()\n",
    "\n",
    "# print(\"A\")\n",
    "\n",
    "# for wlLine in wlFile:\n",
    "#     tokens = wlLine.rstrip().split(\";\")\n",
    "#     result = {'entry': tokens[0]}\n",
    "#     entry = tokens[0]\n",
    "#     if (len(tokens) == 2):\n",
    "#         result['score'] = int(tokens[1])\n",
    "#     else:\n",
    "#         result['score'] = 50\n",
    "#     if (entry not in results):\n",
    "#         results[entry] = result\n",
    "#         resultKeys.append(entry)\n",
    "#     #i += 1\n",
    "#     #if (i > 10):\n",
    "#     #    break\n",
    "\n",
    "# resultKeys.sort()\n",
    "\n",
    "# print(\"B\")\n",
    "\n",
    "# for entry in resultKeys:\n",
    "#     if (i % 100000 == 0):\n",
    "#         print(i)\n",
    "#     result = results[entry]\n",
    "#     while(True):\n",
    "#         #print(podLine)\n",
    "#         search = re.search('^([A-Z]+),\\\"(.*)\\\",([\\d]+)', podLine)\n",
    "#         podEntry = search.group(1)\n",
    "#         if (podEntry < entry):\n",
    "#             #print(\"L\")\n",
    "#             podLine = podcastFile.readline()\n",
    "#             continue\n",
    "#         if (podEntry == entry):\n",
    "#             #print(\"E\")\n",
    "#             r = search.group(2).strip()\n",
    "#             #r = r.upper()\n",
    "#             r = r.lower()\n",
    "#             #r = re.sub('[^A-Z ]', '', r)\n",
    "#             r = re.sub('  ', ' ', r)\n",
    "#             r = re.sub('^ ', '', r)\n",
    "#             #r = re.sub(' ', '-', r)\n",
    "#             result['spacedEntry'] = r\n",
    "#             podLine = podcastFile.readline()\n",
    "#             break\n",
    "#         if (podEntry > entry):\n",
    "#             #print(\"G\")\n",
    "#             result['spacedEntry'] = entry.lower()\n",
    "#             break\n",
    "#     i += 1\n",
    "\n",
    "# print(\"C\")\n",
    "\n",
    "# for entry in resultKeys:\n",
    "#     result = results[entry]\n",
    "#     #print(f\"{result['spacedEntry']};{result['score']}\", file=outputFile)\n",
    "#     #print(f\"{result['entry']},\\\"{result['spacedEntry']}\\\",{result['score']}\", file=outputFile)\n",
    "#     print(f\"{result['entry']};{result['score']}\", file=outputFile)\n",
    "\n",
    "# print(\"D\")\n",
    "\n",
    "# podcastFile.close()\n",
    "# wlFile.close()\n",
    "# outputFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# podcastFilename = \"C:\\\\Users\\\\ben_z\\\\Desktop\\\\entriesData\\\\podcasts_merged.txt\"\n",
    "# wlFilename = \"C:\\\\Users\\\\ben_z\\\\Desktop\\\\rectifiedWordListNew.dict\"\n",
    "# outputFilename = \"C:\\\\Users\\\\ben_z\\\\Desktop\\\\newWords.dict\"\n",
    "# wlKeys = {}\n",
    "# results = {}\n",
    "# scores = {}\n",
    "# i = 0\n",
    "\n",
    "# wlFile = open(wlFilename)\n",
    "# podcastFile = open(podcastFilename)\n",
    "# outputFile = open(outputFilename, 'w')\n",
    "# podLine = podcastFile.readline()\n",
    "\n",
    "# print(\"A\")\n",
    "\n",
    "# for wlLine in wlFile:\n",
    "#     tokens = wlLine.rstrip().split(\";\")\n",
    "#     result = {'entry': tokens[0]}\n",
    "#     entry = tokens[0]\n",
    "#     wlKeys[entry] = True\n",
    "#     # if (len(tokens) == 2):\n",
    "#     #     result['score'] = int(tokens[1])\n",
    "#     # else:\n",
    "#     #     result['score'] = 50\n",
    "#     # if (entry not in results):\n",
    "#     #     results[entry] = result\n",
    "#     #     resultKeys.append(entry)\n",
    "#     #i += 1\n",
    "#     #if (i > 10):\n",
    "#     #    break\n",
    "\n",
    "# print(\"B\")\n",
    "\n",
    "# while(True):\n",
    "#     # if (i > 1000):\n",
    "#     #     break\n",
    "#     if (i % 100000 == 0):\n",
    "#         print(i)\n",
    "\n",
    "#     podLine = podcastFile.readline()\n",
    "#     if (not podLine or len(podLine) == 0):\n",
    "#         break\n",
    "#     search = re.search('^([A-Z]+),\\\"(.*)\\\",([\\d]+)', podLine)\n",
    "#     entry = search.group(1)\n",
    "#     score = int(search.group(3))\n",
    "\n",
    "#     if (entry not in wlKeys and score >= 20):\n",
    "#         results[entry] = {\"entry\": entry, \"display\": search.group(2), \"score\": score}\n",
    "#         scores[entry] = score\n",
    "\n",
    "#     i += 1\n",
    "\n",
    "# s = sorted(scores, key=scores.get, reverse=True)\n",
    "\n",
    "# print(\"C\")\n",
    "\n",
    "# for key in s:\n",
    "#     result = results[key]\n",
    "#     print(f\"{result['display']}\\t\\t\\t,{result['entry']},{result['score']}\", file=outputFile)\n",
    "\n",
    "# print(\"D\")\n",
    "\n",
    "# podcastFile.close()\n",
    "# wlFile.close()\n",
    "# outputFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{5+5}\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "804c09ffedd49315bd312a17c76bd70e47ad9c625880ee8d63fd252686f06c39"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "metadata": {
   "interpreter": {
    "hash": "804c09ffedd49315bd312a17c76bd70e47ad9c625880ee8d63fd252686f06c39"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
